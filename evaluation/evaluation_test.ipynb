{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install octis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import octis\n",
    "import pandas as pd\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..\\\\data\\\\clean\\\\des_b64_wit_kag_0_of_48.tsv'\n",
    "\n",
    "df = pd.read_table(path)\n",
    "images = df['b64_bytes'].apply(lambda x: BytesIO(base64.b64decode(x)))\n",
    "\n",
    "image_list = images.to_list()\n",
    "\n",
    "texts = df['context_page_description'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.dataset.dataset import Dataset\n",
    "dataset = Dataset()\n",
    "dataset.fetch_dataset(\"20NewsGroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.models.LDA import LDA\n",
    "model = LDA(num_topics=10)\n",
    "model_output = model.train_model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "metric = TopicDiversity(topk=10)\n",
    "topic_diversity_score = metric.score(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    enc = text.encode('utf-8')\n",
    "    enc.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cp1252'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "enc = locale.getpreferredencoding()\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = r'..\\myfile.txt'\n",
    "text = \"\\n\".join(texts)\n",
    "text = text.encode('cp1252', 'ignore').decode('cp1252', 'ignore')\n",
    "with open(txt_file, mode='wt') as file:\n",
    "    file.write(text)\n",
    "\n",
    "with open(txt_file) as f:\n",
    "    content = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "import string\n",
    "preprocessor = Preprocessing(\n",
    "                lowercase=False,\n",
    "                remove_punctuation=False,\n",
    "                punctuation=string.punctuation,\n",
    "                remove_numbers=False,\n",
    "                lemmatize=False,\n",
    "                language=\"english\",\n",
    "                split=False,\n",
    "                verbose=True,\n",
    "                save_original_indexes=True,\n",
    "                remove_stopwords_spacy=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created vocab\n",
      "18890\n",
      "words filtering done\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"custom_octis_dataset\"\n",
    "dataset = preprocessor.preprocess_dataset(documents_path=txt_file)\n",
    "dataset.save(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = output_folder+'/vocabulary.txt'\n",
    "with open(vocab, encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "content = content.encode('cp1252', 'ignore').decode('cp1252', 'ignore')\n",
    "with open(vocab, mode='wt') as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = Dataset()\n",
    "custom_dataset.load_custom_dataset_from_folder(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LDA(num_topics=10)  # Create model\n",
    "model_output2 = model2.train_model(custom_dataset) # Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = metric.score(model_output2)\n",
    "score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octis with multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\Martin\\\\Documents\\\\GitHub\\\\master\\\\modeling')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multimodal\n",
    "import c_tf_idf\n",
    "import multimodalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, custom_dataset_folder, params, top_k = 10):\n",
    "        self.model = None\n",
    "        self.folder = custom_dataset_folder\n",
    "        self.top_k = top_k\n",
    "        self.data = self.get_dataset()\n",
    "        \n",
    "        self.metrics = self.get_metrics()\n",
    "        self.params = params\n",
    "        \n",
    "        \n",
    "    def train(self, params):\n",
    "        self.model = multimodalModel.MultimodalModel(**params)\n",
    "        topics = self.model.fit_transform()\n",
    "        all_words = [word for words in self.data.get_corpus() for word in words]\n",
    "        bertopic_topics = [\n",
    "            [\n",
    "                vals if vals in all_words else all_words[0]\n",
    "                for vals in self.model.get_topic(i)\n",
    "            ]\n",
    "            for i in range(len(set(topics)) - 1)\n",
    "        ]\n",
    "\n",
    "        output_tm = {\"topics\": bertopic_topics}\n",
    "        return output_tm\n",
    "\n",
    "\n",
    "    def evaluate(self, model_output, verbose=True):\n",
    "        results = {}\n",
    "        for scorers,_ in self.metrics:\n",
    "            for scorer, name in scorers:\n",
    "                score = scorer.score(model_output)\n",
    "                results[name]=float(score)\n",
    "        if verbose:\n",
    "            for metric, score in results.items():\n",
    "                print(f'{metric}:{str(score)}')\n",
    "        return results\n",
    "        \n",
    "    \n",
    "    def get_dataset(self):\n",
    "        data = Dataset()\n",
    "        data.load_custom_dataset_from_folder(self.folder)\n",
    "        return data\n",
    "\n",
    "    def get_metrics(self):\n",
    "        npmi = Coherence(texts = self.data.get_corpus(), topk=self.top_k, measure=\"c_npmi\")\n",
    "        topic_diversity = TopicDiversity(topk=self.top_k)\n",
    "\n",
    "        coherence= [(npmi, \"npmi\")]\n",
    "        diversity = [(topic_diversity, \"diversity\")]\n",
    "\n",
    "        metrics = [(coherence, \"Coherence\"), (diversity, \"Diversity\")]\n",
    "        return metrics\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "100%|██████████| 18/18 [00:11<00:00,  1.56it/s]\n",
      "100%|██████████| 18/18 [00:17<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "path = '..\\\\data\\\\clean\\\\des_b64_wit_kag_0_of_48.tsv'\n",
    "texts, images = multimodal.get_image_and_text_from_file(path)\n",
    "text_embed = multimodal.get_embeddings_from_text(texts, embedding_model)\n",
    "image_embed = multimodal.get_embeddings_from_images(images, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'path_to_data':'..\\\\data\\\\clean\\\\des_b64_wit_kag_0_of_48.tsv',\n",
    "'embedding_model':SentenceTransformer(\"clip-ViT-B-32\"),\n",
    "\n",
    "'precomputed_text_embeds':text_embed,\n",
    "'precomputed_image_embeds':image_embed\n",
    "}\n",
    "folder = output_folder\n",
    "trainer = Trainer(custom_dataset_folder = folder,  params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Martin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 16220/16220 [00:02<00:00, 7918.61it/s]\n",
      "100%|██████████| 16220/16220 [00:23<00:00, 694.80it/s]\n",
      "100%|██████████| 16220/16220 [00:00<00:00, 190823.44it/s]\n"
     ]
    }
   ],
   "source": [
    "output = trainer.train(trainer.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmi:0.8251784611429603\n",
      "diversity:0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'npmi': 0.8251784611429603, 'diversity': 0.2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = [word for words in trainer.data.get_corpus() for word in words]\n",
    "\"part\" in all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['part',\n",
       "  'town',\n",
       "  'area',\n",
       "  'township',\n",
       "  'city',\n",
       "  'states',\n",
       "  'census',\n",
       "  'county',\n",
       "  'population',\n",
       "  'united'],\n",
       " ['county',\n",
       "  'one',\n",
       "  'station',\n",
       "  'district',\n",
       "  'united',\n",
       "  'also',\n",
       "  'first',\n",
       "  'located',\n",
       "  'city',\n",
       "  'known']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.top_terms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1d88f1d6af7274392319340ad589157e5034eb25853bd7ff5b502ff0dd39369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
