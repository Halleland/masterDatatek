{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install octis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import octis\n",
    "import pandas as pd\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..\\\\data\\\\clean\\\\des_b64_wit_kag_0_of_48.tsv'\n",
    "\n",
    "df = pd.read_table(path)\n",
    "images = df['b64_bytes'].apply(lambda x: BytesIO(base64.b64decode(x)))\n",
    "\n",
    "image_list = images.to_list()\n",
    "\n",
    "texts = df['context_page_description'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.dataset.dataset import Dataset\n",
    "dataset = Dataset()\n",
    "dataset.fetch_dataset(\"20NewsGroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.models.LDA import LDA\n",
    "model = LDA(num_topics=10)\n",
    "model_output = model.train_model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "metric = TopicDiversity(topk=10)\n",
    "topic_diversity_score = metric.score(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    enc = text.encode('utf-8')\n",
    "    enc.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cp1252'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "enc = locale.getpreferredencoding()\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = r'..\\myfile.txt'\n",
    "text = \"\\n\".join(texts)\n",
    "text = text.encode('cp1252', 'ignore').decode('cp1252', 'ignore')\n",
    "with open(txt_file, mode='wt') as file:\n",
    "    file.write(text)\n",
    "\n",
    "with open(txt_file) as f:\n",
    "    content = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "import string\n",
    "preprocessor = Preprocessing(\n",
    "                lowercase=False,\n",
    "                remove_punctuation=False,\n",
    "                punctuation=string.punctuation,\n",
    "                remove_numbers=False,\n",
    "                lemmatize=False,\n",
    "                language=\"english\",\n",
    "                split=False,\n",
    "                verbose=True,\n",
    "                save_original_indexes=True,\n",
    "                remove_stopwords_spacy=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created vocab\n",
      "18890\n",
      "words filtering done\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"custom_octis_dataset\"\n",
    "dataset = preprocessor.preprocess_dataset(documents_path=txt_file)\n",
    "dataset.save(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = output_folder+'/vocabulary.txt'\n",
    "with open(vocab, encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "content = content.encode('cp1252', 'ignore').decode('cp1252', 'ignore')\n",
    "with open(vocab, mode='wt') as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = Dataset()\n",
    "custom_dataset.load_custom_dataset_from_folder(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LDA(num_topics=10)  # Create model\n",
    "model_output2 = model2.train_model(custom_dataset) # Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = metric.score(model_output2)\n",
    "score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octis with multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\Martin\\\\Documents\\\\GitHub\\\\master\\\\modeling')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multimodal\n",
    "import c_tf_idf\n",
    "import multimodalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, custom_dataset_folder, params, top_k = 10):\n",
    "        self.model = None\n",
    "        self.folder = custom_dataset_folder\n",
    "        self.top_k = top_k\n",
    "        self.data = self.get_dataset()\n",
    "        \n",
    "        self.metrics = self.get_metrics()\n",
    "        self.params = params\n",
    "        \n",
    "        \n",
    "    def train(self, params):\n",
    "        self.model = multimodalModel.MultimodalModel(**params)\n",
    "        topics = self.model.fit_transform()\n",
    "        all_words = [word for words in self.data.get_corpus() for word in words]\n",
    "        bertopic_topics = [\n",
    "            [\n",
    "                vals if vals in all_words else all_words[0]\n",
    "                for vals in self.model.get_topic(i)\n",
    "            ]\n",
    "            for i in range(len(set(topics)) - 1)\n",
    "        ]\n",
    "\n",
    "        output_tm = {\"topics\": bertopic_topics}\n",
    "        return output_tm\n",
    "\n",
    "\n",
    "    def evaluate(self, model_output, verbose=True):\n",
    "        results = {}\n",
    "        for scorers,_ in self.metrics:\n",
    "            for scorer, name in scorers:\n",
    "                score = scorer.score(model_output)\n",
    "                results[name]=float(score)\n",
    "        if verbose:\n",
    "            for metric, score in results.items():\n",
    "                print(f'{metric}:{str(score)}')\n",
    "        return results\n",
    "        \n",
    "    \n",
    "    def get_dataset(self):\n",
    "        data = Dataset()\n",
    "        data.load_custom_dataset_from_folder(self.folder)\n",
    "        return data\n",
    "\n",
    "    def get_metrics(self):\n",
    "        npmi = Coherence(texts = self.data.get_corpus(), topk=self.top_k, measure=\"c_npmi\")\n",
    "        topic_diversity = TopicDiversity(topk=self.top_k)\n",
    "\n",
    "        coherence= [(npmi, \"npmi\")]\n",
    "        diversity = [(topic_diversity, \"diversity\")]\n",
    "\n",
    "        metrics = [(coherence, \"Coherence\"), (diversity, \"Diversity\")]\n",
    "        return metrics\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "100%|██████████| 18/18 [00:11<00:00,  1.56it/s]\n",
      "100%|██████████| 18/18 [00:17<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "path = '..\\\\data\\\\clean\\\\des_b64_wit_kag_0_of_48.tsv'\n",
    "texts, images = multimodal.get_image_and_text_from_file(path)\n",
    "text_embed = multimodal.get_embeddings_from_text(texts, embedding_model)\n",
    "image_embed = multimodal.get_embeddings_from_images(images, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = {'path_to_data':'..\\\\data\\\\clean\\\\des_b64_wit_kag_0_of_48.tsv',\n",
    "'embedding_model':SentenceTransformer(\"clip-ViT-B-32\"),\n",
    "\n",
    "'precomputed_text_embeds':text_embed,\n",
    "'precomputed_image_embeds':image_embed\n",
    "}\n",
    "folder = output_folder\n",
    "trainer = Trainer(custom_dataset_folder = folder,  params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Martin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 16220/16220 [00:01<00:00, 11318.91it/s]\n",
      "100%|██████████| 16220/16220 [00:00<00:00, 17329.08it/s]\n",
      "100%|██████████| 16220/16220 [00:00<00:00, 27965.41it/s]\n",
      "100%|██████████| 16220/16220 [00:06<00:00, 2557.55it/s]\n",
      "100%|██████████| 16220/16220 [00:00<00:00, 18773.14it/s]\n",
      "100%|██████████| 16220/16220 [00:00<00:00, 27679.18it/s]\n",
      "100%|██████████| 16220/16220 [00:00<00:00, 53887.36it/s]\n",
      "100%|██████████| 16220/16220 [00:01<00:00, 13471.78it/s]\n",
      "100%|██████████| 16220/16220 [00:00<00:00, 22877.27it/s]\n",
      "100%|██████████| 16220/16220 [00:01<00:00, 12014.83it/s]\n",
      "100%|██████████| 16220/16220 [00:00<00:00, 225282.17it/s]\n"
     ]
    }
   ],
   "source": [
    "output = trainer.train(trainer.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmi:-0.19851895701409147\n",
      "diversity:0.7777777777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'npmi': -0.19851895701409147, 'diversity': 0.7777777777777778}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmi:-0.035532260439734085\n",
      "diversity:0.24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'npmi': -0.035532260439734085, 'diversity': 0.24}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(model_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'of', 'a', 'is', 'in', 'was', 'and', 'The', 'Islands', 'as'],\n",
       " ['the', 'and', 'of', 'was', 'in', 'a', 'is', 'to', 'as', 'The'],\n",
       " ['of', 'the', 'in', 'is', 'a', 'to', 'was', 'and', 'It', 'The'],\n",
       " ['in', 'the', 'is', 'of', 'a', 'The', 'was', 'reserve', 'population', 'It'],\n",
       " ['and', 'the', 'is', 'Iowa', 'of', 'in', 'a', 'The', '92', 'Gorj'],\n",
       " ['the', 'is', 'a', 'in', 'of', 'and', 'was', 'It', 'as', 'to'],\n",
       " ['the', 'of', 'in', 'is', 'a', 'and', 'The', 'was', 'to', 'It'],\n",
       " ['the', 'and', 'of', 'in', 'a', 'was', 'is', 'to', 'by', 'as'],\n",
       " ['a', 'is', 'the', 'of', 'and', 'in', 'was', 'amateur', 'Cuban', 'light'],\n",
       " ['a',\n",
       "  'is',\n",
       "  'dwelling',\n",
       "  'the',\n",
       "  'in',\n",
       "  'was',\n",
       "  'of',\n",
       "  'and',\n",
       "  'medalist',\n",
       "  'Willem']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output2['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topics': [['part',\n",
       "   'township',\n",
       "   'town',\n",
       "   'area',\n",
       "   'city',\n",
       "   'united',\n",
       "   'states',\n",
       "   'population',\n",
       "   'county',\n",
       "   'census'],\n",
       "  ['endemic',\n",
       "   'bird',\n",
       "   'plant',\n",
       "   'Scolopendra',\n",
       "   'found',\n",
       "   'family',\n",
       "   'native',\n",
       "   'genus',\n",
       "   'species',\n",
       "   'known'],\n",
       "  ['service',\n",
       "   'class',\n",
       "   'world',\n",
       "   'states',\n",
       "   'united',\n",
       "   'Scolopendra',\n",
       "   'ship',\n",
       "   'built',\n",
       "   'war',\n",
       "   'navy'],\n",
       "  ['population',\n",
       "   'area',\n",
       "   'church',\n",
       "   'building',\n",
       "   'south',\n",
       "   'district',\n",
       "   'station',\n",
       "   'located',\n",
       "   'city',\n",
       "   'county'],\n",
       "  ['division',\n",
       "   'guard',\n",
       "   'city',\n",
       "   'force',\n",
       "   'district',\n",
       "   'national',\n",
       "   'asteroid',\n",
       "   'order',\n",
       "   'municipality',\n",
       "   'army'],\n",
       "  ['football',\n",
       "   'league',\n",
       "   'national',\n",
       "   'plays',\n",
       "   'played',\n",
       "   'basketball',\n",
       "   'team',\n",
       "   'professional',\n",
       "   'player',\n",
       "   'footballer'],\n",
       "  ['festival',\n",
       "   'fought',\n",
       "   'Scolopendra',\n",
       "   'Scolopendra',\n",
       "   'saint',\n",
       "   'marriage',\n",
       "   'countess',\n",
       "   'holy',\n",
       "   'Scolopendra',\n",
       "   'la'],\n",
       "  ['member',\n",
       "   'albums',\n",
       "   'music',\n",
       "   'best',\n",
       "   'rock',\n",
       "   'actress',\n",
       "   'singer',\n",
       "   'band',\n",
       "   'american',\n",
       "   'known'],\n",
       "  ['politician',\n",
       "   'later',\n",
       "   'states',\n",
       "   'Scolopendra',\n",
       "   'united',\n",
       "   'war',\n",
       "   'film',\n",
       "   'american',\n",
       "   'Scolopendra',\n",
       "   'served']]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1d88f1d6af7274392319340ad589157e5034eb25853bd7ff5b502ff0dd39369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
